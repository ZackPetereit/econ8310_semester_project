{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b0fe2-5d15-4cc5-9714-e1d7d859d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to load and clean one file\n",
    "def load_and_clean_ecec_file(file_path, year):\n",
    "    df_raw = pd.read_excel(file_path, header=[0, 1], skiprows=5)\n",
    "\n",
    "    # Split into metadata and timestamps\n",
    "    meta_df = df_raw.iloc[:, :7].copy()\n",
    "    timestamps_df = df_raw.iloc[:, 7:].copy()\n",
    "\n",
    "    # Flatten column names\n",
    "    meta_df.columns = ['_'.join([str(c) for c in col if 'Unnamed' not in str(c)]).strip() for col in meta_df.columns]\n",
    "    timestamps_df.columns = [f\"{str(c[0]).strip()}_{str(c[1]).strip()}\" for c in timestamps_df.columns]\n",
    "\n",
    "    # Add row index for merge\n",
    "    meta_df['row_id'] = meta_df.index\n",
    "    timestamps_df['row_id'] = timestamps_df.index\n",
    "\n",
    "    # Melt timestamp columns\n",
    "    long_df = timestamps_df.melt(id_vars='row_id', var_name='date_inout', value_name='timestamp')\n",
    "    long_df[['date_str', 'in_out']] = long_df['date_inout'].str.extract(r'(.*)_(IN|OUT)', expand=True)\n",
    "\n",
    "    # Add year and convert to datetime\n",
    "    long_df['date_str'] = long_df['date_str'].str.strip() + f' {year}'\n",
    "    long_df['date'] = pd.to_datetime(long_df['date_str'], format='%b %d %Y', errors='coerce')\n",
    "\n",
    "    # Pivot to get IN and OUT columns\n",
    "    pivot_df = long_df.pivot_table(index=['row_id', 'date'], columns='in_out', values='timestamp', aggfunc='first').reset_index()\n",
    "\n",
    "    for col in ['IN', 'OUT']:\n",
    "        if col not in pivot_df.columns:\n",
    "            pivot_df[col] = pd.NaT\n",
    "\n",
    "    # Merge with metadata\n",
    "    final_df = pivot_df.merge(meta_df, on='row_id', how='left')\n",
    "\n",
    "    # Clean time strings\n",
    "    def clean_time_only(x):\n",
    "        if pd.isna(x):\n",
    "            return x\n",
    "        match = re.match(r'^\\s*\\d{1,2}:\\d{2}\\s*(AM|PM)', str(x), re.IGNORECASE)\n",
    "        return match.group(0) if match else x\n",
    "\n",
    "    final_df['IN'] = final_df['IN'].apply(clean_time_only)\n",
    "    final_df['OUT'] = final_df['OUT'].apply(clean_time_only)\n",
    "\n",
    "    # Add year column for tracking\n",
    "    final_df['year'] = int(year)\n",
    "\n",
    "    return final_df[['Record ID', 'Student Status', 'Room', 'Tags', 'date', 'IN', 'OUT', 'year']]\n",
    "\n",
    "# File URLs and corresponding years\n",
    "ecec_files = {\n",
    "    \"2022\": \"https://raw.githubusercontent.com/duehl85/econ8310_semester_project/main/CSIData/ECEC%202022%20Student%20Sign%20In%20and%20Out.xlsx\",\n",
    "    \"2023\": \"https://raw.githubusercontent.com/duehl85/econ8310_semester_project/main/CSIData/ECEC%202023%20Student%20Sign%20In%20and%20Out.xlsx\",\n",
    "    \"2024\": \"https://raw.githubusercontent.com/duehl85/econ8310_semester_project/main/CSIData/ECEC%202024%20Student%20Sign%20In%20and%20Out.xlsx\",\n",
    "    \"2025\": \"https://raw.githubusercontent.com/duehl85/econ8310_semester_project/main/CSIData/ECEC%202025%2001012025-02282025%20Student%20Sign%20In%20and%20Out.xlsx\"\n",
    "}\n",
    "\n",
    "# Process all files and combine\n",
    "all_years_df = pd.concat(\n",
    "    [load_and_clean_ecec_file(path, year) for year, path in ecec_files.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "#regular expression pattern to identify age groups\n",
    "\n",
    "age_group_pattern = r'(Infants|Multi-Age|Toddlers|Preschool|Pre-K)'\n",
    "\n",
    "#extract age group from room name and create new column called age_group\n",
    "\n",
    "all_years_df['age_group'] = all_years_df['Room'].str.extract(age_group_pattern, expand=False)\n",
    "\n",
    "#41 out of 7,515 out entries, there are 41 entries where the timestamp is -- (possibly a student was not clocked out)\n",
    "#0.55% is not a material amount of entries. Treating these out times as NAN\n",
    "\n",
    "all_years_df['OUT'] = all_years_df['OUT'].replace('--', pd.NA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b17b1cfc-a436-40c7-87e1-b8f7387c4f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bd/pql52mvd73zd_wtzsgm40l4h0000gn/T/ipykernel_48960/403524351.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  all_years_df['out_datetime'] = pd.to_datetime(all_years_df['date'].astype(str) + ' ' + all_years_df['OUT'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Make sure IN and OUT are datetime objects\n",
    "all_years_df['in_datetime'] = pd.to_datetime(all_years_df['date'].astype(str) + ' ' + all_years_df['IN'], errors='coerce')\n",
    "all_years_df['out_datetime'] = pd.to_datetime(all_years_df['date'].astype(str) + ' ' + all_years_df['OUT'], errors='coerce')\n",
    "\n",
    "# Drop rows where IN or OUT is missing (or handle imputation later)\n",
    "attended_df = all_years_df.dropna(subset=['in_datetime', 'out_datetime']).copy()\n",
    "\n",
    "# Function to generate 30-min blocks between IN and OUT\n",
    "def generate_30min_blocks(start, end):\n",
    "    return pd.date_range(start=start, end=end, freq='30min').tolist()\n",
    "\n",
    "# Apply to each row\n",
    "attended_df['time_blocks'] = attended_df.apply(lambda row: generate_30min_blocks(row['in_datetime'], row['out_datetime']), axis=1)\n",
    "\n",
    "# Explode so each row = one 30-min block per student\n",
    "expanded_df = attended_df.explode('time_blocks')\n",
    "\n",
    "# Round the block timestamp to the nearest floor 30-min for consistency\n",
    "expanded_df['time_block'] = expanded_df['time_blocks'].dt.floor('30min')\n",
    "\n",
    "# Final attendance time grid: One row = one child in one room at one 30-min block\n",
    "attendance_grid = expanded_df[['Record ID', 'Student Status', 'age_group', 'time_block']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b586f374-6c93-4bc4-821f-efa944cfdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#group students by age group and time block\n",
    "\n",
    "grouped = attendance_grid.groupby(['age_group', 'time_block', 'Student Status']).agg(\n",
    "    children_present=('Record ID', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "#define the student/staff ratios\n",
    "\n",
    "ratio_table = pd.DataFrame({\n",
    "    'age_group': ['Infants', 'Multi-Age', 'Toddlers', 'Preschool', 'Pre-K'],\n",
    "    'student_to_staff': [4, 4, 6, 10, 12]\n",
    "})\n",
    "\n",
    "#merge the two dfs based on age_group\n",
    "\n",
    "grouped = grouped.merge(ratio_table, on='age_group', how='left')\n",
    "\n",
    "#determine staffing required. Use np ceiling function to round up to next integer\n",
    "\n",
    "grouped['staff_required'] = np.ceil(grouped['children_present'] / grouped['student_to_staff']).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "be8a25c6-efd2-4283-ac0e-605c9efb6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_csv(\"ecec_staffing_grouped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd660c-b258-4152-9876-2cc10c734e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
